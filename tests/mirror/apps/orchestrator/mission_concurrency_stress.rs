// INICIO DEL ARCHIVO [apps/orchestrator/tests/mission_concurrency_stress.rs]
/**
 * =================================================================
 * APARATO: MISSION CONCURRENCY STRESS (V1.2 - HYGIENE CLEAN)
 * CLASIFICACIÃ“N: QA INFRAESTRUCTURA (ESTRATO L3)
 * =================================================================
 */

#[cfg(test)]
mod stress_chamber {
    use prospector_orchestrator::state::AppState;
    use prospector_orchestrator::handlers::swarm::SwarmHandshakeHandler;
    use prospector_domain_models::work::{MissionRequestPayload, NodeHardwareCapacity, WorkOrder, SearchStrategy, TargetStrata};
    use prospector_infra_db::TursoClient;
    use axum::extract::{Json, State};
    use axum::response::IntoResponse;
    // âœ… FIX: 'Arc' eliminado (unused import)
    use tokio::task;

    #[tokio::test(flavor = "multi_thread", worker_threads = 4)]
    async fn certify_dispatch_resilience_under_massive_burst() {
        println!("\nðŸ”¥ [STRESS_TEST]: Initiating 1000-unit concurrent burst...");

        let database_client = TursoClient::connect("file::memory:", None).await.unwrap();
        let application_state = AppState::new(database_client);

        let mut mission_batch = Vec::new();
        for i in 0..1000 {
            mission_batch.push(WorkOrder {
                job_mission_identifier: format!("mission-stress-id-{}", i),
                lease_duration_seconds: 600,
                strategy: SearchStrategy::Sequential {
                    start_index_hexadecimal: "0".into(),
                    end_index_hexadecimal: "100".into(),
                },
                required_strata: TargetStrata::SatoshiEra,
            });
        }
        application_state.mission_control.hydrate_queue(mission_batch);

        let mut network_request_handles = vec![];
        let total_concurrent_units = 1000;

        for i in 0..total_concurrent_units {
            let state_snapshot = application_state.clone();
            let handle = task::spawn(async move {
                let payload = MissionRequestPayload {
                    worker_id: format!("hydra-unit-{}", i),
                    hardware_capacity: NodeHardwareCapacity {
                        ram_available_mb: 8192,
                        cpu_cores: 2,
                        supports_avx2: true,
                    }
                };
                SwarmHandshakeHandler::negotiate_mission_assignment_handshake(
                    State(state_snapshot),
                    Json(payload)
                ).await.into_response()
            });
            network_request_handles.push(handle);
        }

        let execution_results = futures::future::join_all(network_request_handles).await;
        let successful_assignments = execution_results.iter().filter(|res| res.is_ok()).count();

        println!("ðŸ“Š [STRESS_METRICS]: Successfully assigned {}/{} missions.", successful_assignments, total_concurrent_units);

        assert_eq!(successful_assignments, total_concurrent_units, "CONCURRENCY_COLLAPSE");
        assert_eq!(application_state.mission_control.get_available_buffer_size(), 0, "LEAK_DETECTED");
    }
}
// FIN DEL ARCHIVO [apps/orchestrator/tests/mission_concurrency_stress.rs]
